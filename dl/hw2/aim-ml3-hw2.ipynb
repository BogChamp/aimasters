{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:51:18.512403Z","iopub.status.busy":"2024-10-20T09:51:18.512053Z","iopub.status.idle":"2024-10-20T09:51:24.269754Z","shell.execute_reply":"2024-10-20T09:51:24.268992Z","shell.execute_reply.started":"2024-10-20T09:51:18.512367Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision import models\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","from torchvision.transforms import v2\n","import wandb\n","from torch.optim import Adam, AdamW\n","from torch.optim.lr_scheduler import MultiStepLR\n","from tqdm import tqdm\n","from pathlib import Path\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:51:36.845515Z","iopub.status.busy":"2024-10-20T09:51:36.844682Z","iopub.status.idle":"2024-10-20T09:51:36.849567Z","shell.execute_reply":"2024-10-20T09:51:36.848678Z","shell.execute_reply.started":"2024-10-20T09:51:36.845475Z"},"trusted":true},"outputs":[],"source":["lr = 0.001\n","EPOCH_NUM = 40\n","BATCH_SIZE = 64\n","weight_decay = 1e-4"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:51:47.871808Z","iopub.status.busy":"2024-10-20T09:51:47.871437Z","iopub.status.idle":"2024-10-20T09:51:47.888589Z","shell.execute_reply":"2024-10-20T09:51:47.887655Z","shell.execute_reply.started":"2024-10-20T09:51:47.871772Z"},"trusted":true},"outputs":[],"source":["class ImageTransform:\n","    def __init__(self, kind):\n","        if kind == 'train':\n","            self.transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n","                                      v2.RandomHorizontalFlip(), v2.RandomVerticalFlip(), v2.GaussianNoise(sigma=0.01),\n","                                      v2.RandomRotation(15), \n","                                      v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","            \n","        else:\n","            self.transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n","                                      v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","\n","    def __call__(self, sample):\n","        return self.transform(sample)\n","\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, path, kind, transform=None, target_transform=None):\n","        self.prepare_image_path(path, kind)\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def prepare_image_path(self, path, kind):\n","        dataset_path = os.path.join(path, kind)\n","        if kind == \"train\":\n","            self.class_to_idx = {}\n","            image_path_list = []\n","            label_list = []\n","            class_list = os.listdir(dataset_path)\n","            class_list.sort()\n","            for i, cls in enumerate(class_list): \n","                self.class_to_idx[cls] = i\n","                cls_images_path = os.path.join(dataset_path, cls + '/images')\n","                image_list = os.listdir(cls_images_path)\n","                for image_name in image_list:\n","                    image_path_list.append(os.path.join(cls_images_path, image_name))\n","                label_list += [i] * len(image_list)\n","\n","        elif kind == \"val\":\n","            image_path_list = []\n","            label_list = []\n","            class_list = os.listdir(dataset_path)\n","            class_list.sort()\n","            for i, cls in enumerate(class_list):# to work properly, needed to create map name to int, using train info data\n","                cls_images_path = os.path.join(dataset_path, cls)\n","                image_list = os.listdir(cls_images_path)\n","                for image_name in image_list:\n","                    image_path_list.append(os.path.join(cls_images_path, image_name))\n","                label_list += [i] * len(image_list)\n","\n","        elif kind == \"test\":\n","            image_path_list = []\n","            images_path = os.path.join(dataset_path, 'images')\n","            image_list = os.listdir(images_path)\n","            for image_name in image_list:\n","                image_path_list.append(os.path.join(images_path, image_name))\n","            label_list = None\n","\n","        else:\n","            raise Exception(\"wrong kind argument!!!\")\n","    \n","        self.image_path_list = image_path_list\n","        self.label_list = label_list\n","\n","    def __len__(self):\n","        return len(self.image_path_list)\n","\n","    def __getitem__(self, idx):\n","        image = cv2.imread(self.image_path_list[idx])\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.label_list:\n","            label = self.label_list[idx]\n","        else:\n","            label = -1\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label\n","\n","\n","def get_dataloader(path, kind):\n","    dataset = CustomImageDataset(path, kind, ImageTransform(kind), torch.tensor)\n","    shuffle = True if kind == 'train' else False\n","    return DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=shuffle)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:51:50.305535Z","iopub.status.busy":"2024-10-20T09:51:50.305139Z","iopub.status.idle":"2024-10-20T09:51:50.315263Z","shell.execute_reply":"2024-10-20T09:51:50.314336Z","shell.execute_reply.started":"2024-10-20T09:51:50.305499Z"},"trusted":true},"outputs":[],"source":["from urllib.request import urlretrieve\n","\n","def download_dataset(path, url='http://cs231n.stanford.edu/tiny-imagenet-200.zip'):\n","    dataset_name = 'tiny-imagenet-200'\n","\n","    if os.path.exists(os.path.join(path, dataset_name, \"val\", \"n01443537\")):\n","        print(\"%s already exists, skipping download\" % os.path.join(path, dataset_name))\n","        return\n","    elif not os.path.exists(os.path.join(path, 'tiny-imagenet-200' + \".zip\")):\n","        print(\"Dataset doesn't exist or is broken, downloading it\")\n","        urlretrieve(url, os.path.join(path, dataset_name + \".zip\"))\n","\n","    import zipfile\n","    with zipfile.ZipFile(os.path.join(path, 'tiny-imagenet-200' + \".zip\"), 'r') as archive:\n","        archive.extractall()\n","\n","    # move validation images to subfolders by class\n","    val_root = os.path.join(\".\", dataset_name, \"val\")\n","    with open(os.path.join(val_root, \"val_annotations.txt\"), 'r') as f:\n","        for image_filename, class_name, _, _, _, _ in map(str.split, f):\n","            class_path = os.path.join(val_root, class_name)\n","            os.makedirs(class_path, exist_ok=True)\n","            os.rename(\n","                os.path.join(val_root, \"images\", image_filename),\n","                os.path.join(class_path, image_filename))\n","\n","    os.rmdir(os.path.join(val_root, \"images\"))\n","    os.remove(os.path.join(val_root, \"val_annotations.txt\"))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:32:36.515438Z","iopub.status.busy":"2024-10-20T09:32:36.515007Z","iopub.status.idle":"2024-10-20T09:40:54.128501Z","shell.execute_reply":"2024-10-20T09:40:54.127205Z","shell.execute_reply.started":"2024-10-20T09:32:36.515389Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["./tiny-imagenet-200 already exists, skipping download\n"]}],"source":["AUX_DATA_ROOT = Path(\".\")\n","download_dataset(AUX_DATA_ROOT)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:52:01.413723Z","iopub.status.busy":"2024-10-20T09:52:01.412987Z","iopub.status.idle":"2024-10-20T09:52:01.721799Z","shell.execute_reply":"2024-10-20T09:52:01.720814Z","shell.execute_reply.started":"2024-10-20T09:52:01.413677Z"},"trusted":true},"outputs":[],"source":["root_datasets = \"./\"\n","\n","train_dataloader = get_dataloader(f\"{root_datasets}/tiny-imagenet-200/\", 'train')\n","val_dataloader   = get_dataloader(f\"{root_datasets}/tiny-imagenet-200/\", 'val')\n","test_dataloader = get_dataloader(f\"{root_datasets}/tiny-imagenet-200/\", 'test')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:52:05.055990Z","iopub.status.busy":"2024-10-20T09:52:05.054847Z","iopub.status.idle":"2024-10-20T09:52:06.199320Z","shell.execute_reply":"2024-10-20T09:52:06.198408Z","shell.execute_reply.started":"2024-10-20T09:52:05.055934Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbogdan_aleksandrov\u001b[0m (\u001b[33mbogdan_aleksandrov-no\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/b0gcham5/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login(key=\"c86834f3fe7719b70c289274009689f98e6f5c1d\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:52:10.040692Z","iopub.status.busy":"2024-10-20T09:52:10.039704Z","iopub.status.idle":"2024-10-20T09:52:13.805687Z","shell.execute_reply":"2024-10-20T09:52:13.804831Z","shell.execute_reply.started":"2024-10-20T09:52:10.040649Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3938fb2ee9274a188f334c1aee03a297","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111970888891341, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/b0gcham5/aimasters/dl/hw2/wandb/run-20241021_182722-tvzumbut</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2/runs/tvzumbut' target=\"_blank\">grateful-voice-34</a></strong> to <a href='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2' target=\"_blank\">https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2/runs/tvzumbut' target=\"_blank\">https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2/runs/tvzumbut</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2/runs/tvzumbut?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f4672dc58d0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"aim_ml3_hw2\",\n","\n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": lr,\n","    \"architecture\": \"resnet34\",\n","    \"dataset\": \"tiny-imagenet-200\",\n","    \"epochs\": EPOCH_NUM,\n","    \"batch_size\": BATCH_SIZE,\n","    \"optim\": \"Adam\",\n","    \"transform\": \"noise+scheduler\"\n","    }\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:52:18.894103Z","iopub.status.busy":"2024-10-20T09:52:18.893633Z","iopub.status.idle":"2024-10-20T09:52:19.896835Z","shell.execute_reply":"2024-10-20T09:52:19.895957Z","shell.execute_reply.started":"2024-10-20T09:52:18.894051Z"},"trusted":true},"outputs":[],"source":["model = models.resnet50(weights=None, num_classes=200)\n","model.to('cuda')\n","pass"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:52:26.992658Z","iopub.status.busy":"2024-10-20T09:52:26.991642Z","iopub.status.idle":"2024-10-20T09:52:26.999492Z","shell.execute_reply":"2024-10-20T09:52:26.998588Z","shell.execute_reply.started":"2024-10-20T09:52:26.992616Z"},"trusted":true},"outputs":[],"source":["optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","criterion = nn.CrossEntropyLoss()\n","scheduler = MultiStepLR(optimizer, milestones=[15, 25], gamma=0.5)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T09:52:44.975880Z","iopub.status.busy":"2024-10-20T09:52:44.975497Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1563 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1563/1563 [07:10<00:00,  3.63it/s]\n","100%|██████████| 1563/1563 [07:53<00:00,  3.30it/s]\n"," 18%|█▊        | 277/1563 [02:45<12:49,  1.67it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 17\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m total_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy\n\u001b[1;32m     19\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["prev_val_acc = 0\n","for i in range(EPOCH_NUM):\n","    total_acc = 0\n","    total_loss = 0\n","    total_n = 0\n","    model.train()\n","    for X, y in tqdm(train_dataloader):\n","        X = X.to('cuda')\n","        y = y.to('cuda')\n","\n","        out = model(X)\n","        loss = criterion(out, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        accuracy = (out.argmax(1) == y).sum().item()\n","        total_acc += accuracy\n","        total_loss += loss.item() * X.shape[0]\n","        total_n += X.shape[0]\n","\n","    train_acc = total_acc / total_n\n","    train_loss = total_loss / total_n\n","\n","    total_acc = 0\n","    total_loss = 0\n","    total_n = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for X, y in val_dataloader:\n","            X = X.to('cuda')\n","            y = y.to('cuda')\n","\n","            out = model(X)\n","            loss = criterion(out, y)\n","            accuracy = (out.argmax(1) == y).sum().item()\n","\n","            total_acc += accuracy\n","            total_loss += loss.item() * X.shape[0]\n","            total_n += X.shape[0]\n","\n","    if scheduler:\n","        scheduler.step()\n","    wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \n","               \"val_acc\": total_acc / total_n, \"val_loss\": total_loss / total_n})\n","\n","    if (total_acc / total_n > prev_val_acc):\n","        prev_val_acc = total_acc / total_n\n","        torch.save({\n","            'epoch': i,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'acc': prev_val_acc,\n","            }, 'checkpoint.pth')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.14002</td></tr><tr><td>train_loss</td><td>3.93015</td></tr><tr><td>val_acc</td><td>0.1646</td></tr><tr><td>val_loss</td><td>3.86756</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">grateful-voice-34</strong> at: <a href='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2/runs/tvzumbut' target=\"_blank\">https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2/runs/tvzumbut</a><br/> View project at: <a href='https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2' target=\"_blank\">https://wandb.ai/bogdan_aleksandrov-no/aim_ml3_hw2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241021_182722-tvzumbut/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: gdown==4.4.0 in /home/b0gcham5/.local/lib/python3.11/site-packages (4.4.0)\n","Requirement already satisfied: filelock in /home/b0gcham5/.local/lib/python3.11/site-packages (from gdown==4.4.0) (3.16.1)\n","Requirement already satisfied: requests[socks] in /home/b0gcham5/.local/lib/python3.11/site-packages (from gdown==4.4.0) (2.32.3)\n","Requirement already satisfied: six in /home/b0gcham5/.local/lib/python3.11/site-packages (from gdown==4.4.0) (1.16.0)\n","Requirement already satisfied: tqdm in /home/b0gcham5/.local/lib/python3.11/site-packages (from gdown==4.4.0) (4.66.5)\n","Requirement already satisfied: beautifulsoup4 in /home/b0gcham5/.local/lib/python3.11/site-packages (from gdown==4.4.0) (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in /home/b0gcham5/.local/lib/python3.11/site-packages (from beautifulsoup4->gdown==4.4.0) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/b0gcham5/.local/lib/python3.11/site-packages (from requests[socks]->gdown==4.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /home/b0gcham5/.local/lib/python3.11/site-packages (from requests[socks]->gdown==4.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/b0gcham5/.local/lib/python3.11/site-packages (from requests[socks]->gdown==4.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/b0gcham5/.local/lib/python3.11/site-packages (from requests[socks]->gdown==4.4.0) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/b0gcham5/.local/lib/python3.11/site-packages (from requests[socks]->gdown==4.4.0) (1.7.1)\n"]}],"source":["import pandas as pd\n","from solution import predict"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["model = models.resnet50(weights=None, num_classes=200)\n","pass"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["w = torch.load('checkpoint_17.pth', weights_only=True)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["map_classes = {class_idx: class_name for class_name, class_idx in train_dataloader.dataset.class_to_idx.items()}"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 157/157 [00:08<00:00, 18.64it/s]\n"]}],"source":["pred_dict = {}\n","pred_labels = []\n","model.eval()\n","model.to('cuda')\n","for batch, _ in tqdm(test_dataloader):\n","    with torch.no_grad():\n","        _, predicted_labels = predict(model, batch).max(1)\n","    pred_labels.extend(predicted_labels.tolist())\n","\n","for i, img_name in enumerate(test_dataloader.dataset.image_path_list):\n","    pred_dict[img_name.split(\"/\")[-1]] = map_classes[pred_labels[i]]"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["submission_df = pd.DataFrame(pred_dict.items(), columns=[\"id\", \"pred\"])\n","submission_df.to_csv(\"submission14.csv\", index=False)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1089d094ad7bf904c14058d4ff7103b6  checkpoint.pth\n"]}],"source":["!md5sum checkpoint.pth"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":4}
